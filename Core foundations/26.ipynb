{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dufferent Optimizer 优化方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.random(size=(10000, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrue = torch.from_numpy(np.random.uniform(0, 5, size=(10000, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = torch.nn.Linear(in_features=8, out_features=1)\n",
    "\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "linear2 = torch.nn.Linear(in_features=1, out_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(linear, sigmoid, linear2).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.from_numpy(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 1])\n",
      "torch.Size([10000, 1])\n"
     ]
    }
   ],
   "source": [
    "print(model(train_x).shape)\n",
    "print(ytrue.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.8109, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(11.8062, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(11.7967, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(11.7824, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(11.7635, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(11.7398, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(11.7114, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(11.6784, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(11.6407, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(11.5984, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(11.5515, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(11.5001, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(11.4442, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(11.3838, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(11.3190, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(11.2499, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(11.1765, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(11.0989, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(11.0172, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(10.9313, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(10.8414, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(10.7476, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(10.6499, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(10.5484, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(10.4433, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(10.3345, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(10.2223, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(10.1066, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.9876, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.8654, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.7401, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.6118, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.4807, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.3467, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.2102, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.0711, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.9296, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.7859, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.6400, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.4921, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.3424, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.1910, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.0379, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.8835, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.7278, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.5709, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.4131, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.2545, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.0951, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.9353, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.7752, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.6149, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.4546, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.2945, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.1347, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.9754, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.8169, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.6592, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.5025, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.3471, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.1931, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.0407, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.8901, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.7415, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.5950, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.4508, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.3092, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.1703, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.0343, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.9014, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.7717, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.6455, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.5230, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.4043, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2895, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1790, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.0727, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.9710, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.8740, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.7818, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.6947, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.6127, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.5360, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.4647, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.3991, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.3391, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.2850, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.2369, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.1948, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.1589, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.1292, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.1059, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.0890, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.0786, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.0747, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.0774, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.0867, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.1026, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.1252, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.1545, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# yhat = model(train_x)\n",
    "# loss = loss_fn(yhat, ytrue)\n",
    "# print(loss)\n",
    "\n",
    "optimer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
    "\n",
    "for e in range(100):\n",
    "    yhat = model(train_x)\n",
    "    loss = loss_fn(yhat, ytrue)\n",
    "    loss.backward()\n",
    "    print(loss)\n",
    "    optimer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
