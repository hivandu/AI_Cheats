{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02666667, 0.        , 0.05072262, 0.92261071])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf = DecisionTreeClassifier()\n",
    "tree_clf.fit(x, y)\n",
    "\n",
    "tree_clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "train_x, test_x,train_y, test_y = train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "tree_clf.fit(train_x, train_y)\n",
    "\n",
    "print(tree_clf.score(train_x, train_y))\n",
    "print(tree_clf.score(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fetch_openml(name='boston', version=1, as_frame=True, return_X_y=False, parser='pandas')\n",
    "\n",
    "data = dataset['data']\n",
    "target = dataset['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whole dataset train acc: 1.0\n",
      "whole dataset test acc: 0.6728845239323917\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data, target, test_size=0.3, random_state=0)\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(x_train, y_train)\n",
    "\n",
    "print('whole dataset train acc: {}'.format(tree_reg.score(x_train, y_train)))\n",
    "print('whole dataset test acc: {}'.format(tree_reg.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(x_train, y_train, x_test, y_test, drop_n=4):\n",
    "    features_random = np.random.choice(list(x_train.columns), size=len(x_train.columns)-drop_n)\n",
    "\n",
    "    x_sample = x_train[features_random]\n",
    "    y_sample = y_train\n",
    "\n",
    "    reg = DecisionTreeRegressor()\n",
    "    reg.fit(x_sample, y_sample)\n",
    "\n",
    "    score_train = reg.score(x_sample, y_sample)\n",
    "    score_test = reg.score(x_test[features_random], y_test)\n",
    "\n",
    "    print('sub sample :: train score: {}, test score: {}'.format(score_train, score_test))\n",
    "\n",
    "    y_predicated = reg.predict(x_test[features_random])\n",
    "\n",
    "    return y_predicated, score_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub sample :: train score: 1.0, test score: 0.6784967237312082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([24.1, 50. , 23.2, 16.3, 21.7, 23.1, 22.6, 22. , 23.8, 18.4, 10.8,\n",
       "        17.9, 17.1,  8.8, 50. , 34.9, 16.1, 34.6, 30.1, 22.6, 24.5, 22.7,\n",
       "        20.1, 24.8, 19.7, 20.8, 18.2, 13.1, 43.8, 18.4, 11.7, 13.4, 18.4,\n",
       "        22.2, 23.9, 18.8,  8.3, 50. , 11.7, 17.9, 21.2, 19.7, 23.9, 11.7,\n",
       "        23.9, 23.9, 16. , 18.4, 14.6, 23.8, 18.4, 17.5, 18.2, 48.8, 17.8,\n",
       "        18.9, 17.6, 17.5, 50. , 22.4, 20.6, 18.2, 34.9, 32.4, 11.7, 32.4,\n",
       "        16.4, 18.9, 14.1, 20. , 21.7, 23.9, 23.7, 33.1, 26.5,  8.8, 48.8,\n",
       "        22.2, 22. , 16.8, 23.9, 14.3, 50. , 48.8, 48.8, 25. , 20.6, 11.7,\n",
       "        25. , 12.7, 16. , 11.8, 23.4, 26.6, 22.2, 21.2, 11.9, 23.1, 14.3,\n",
       "        18.5, 25. , 21.7, 29.9, 19.4, 28.5, 19.4,  8.5, 19.9, 20.5, 22.9,\n",
       "        23.9, 17.9, 18.9, 18.3, 18.9, 22.4,  9.5, 19.6, 10.2, 50. , 24.1,\n",
       "         7.2, 16.6, 20.1, 19.4, 20.5, 33.2, 16. , 20.6, 33.2, 12.5,  9.5,\n",
       "        17.8, 18.4, 15. , 34.6, 19.4, 15.6, 23.9,  8.3, 10.2, 20.1, 23.6,\n",
       "        23.7, 24.1, 15.6, 37.3, 37.3, 11.3,  6.3, 32.4, 24.8]),\n",
       " 0.6784967237312082)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest(x_train, y_train, x_test, y_test, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_feature_names = pd.DataFrame(data)\n",
    "with_feature_names.columns = dataset['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(with_feature_names, target, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub sample :: train score: 1.0, test score: 0.21148237274057458\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([21.2,  7.2, 24.6, 12.7, 25.2, 20.4, 12.7, 19. , 13.6, 22.3,  8.5,\n",
       "        13.9, 16.1, 16.3, 50. , 30.3, 19.6, 34.6, 22. , 23.2, 24.6, 20.6,\n",
       "        20.8, 20.1, 18.5, 11.9, 14.8, 15.6, 37.6, 22.6, 12.6, 13.4, 24.7,\n",
       "        20.5, 22.4,  7. , 10.2,  8.5, 13. , 16.1, 20.5, 18.5, 21.2, 11.7,\n",
       "        23.2, 23.9, 18.5, 24.3, 50. , 30.1, 27. , 17.6, 18.2, 41.7, 18.4,\n",
       "        20.9, 19.4, 22. ,  5. , 22.4, 22. , 17.8, 29.6, 25. , 11.7, 22. ,\n",
       "        14.3, 23.1, 14.1, 22.4, 23.4, 23.4, 24.8, 37. , 19.6, 17.9, 41.7,\n",
       "        23.1, 22. , 18.4, 29.1, 19.2, 11.3, 41.7, 48.8, 23.1, 25.3, 11.8,\n",
       "        27. , 12.7, 22. ,  9.6, 22.6, 26.6, 20.3, 22.6, 11.9, 22. , 16.7,\n",
       "        16. , 23.1, 22.3, 29.8, 22.8, 31.1, 20.1, 12.7,  8.1, 20.3, 22. ,\n",
       "        30.7, 11.3, 25.3, 20.3, 17.6, 22.5, 12.7, 16.1, 13.8, 50. , 28. ,\n",
       "        11.3, 18.5, 16.8, 17.8, 23.3, 32.7, 17.6, 16. , 32.7, 16.7, 16.7,\n",
       "        15.2, 23.8, 14.1, 34.6, 17.8, 50. , 25. , 16.7, 10.2, 18.4, 29.8,\n",
       "        27.1, 23.4, 20.4, 37.3, 37.3, 15.1, 11.3, 30.1, 28.4]),\n",
       " 0.21148237274057458)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest(x_train, y_train, x_test, y_test, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub sample :: train score: 1.0, test score: 0.6895030510854971\n",
      "sub sample :: train score: 1.0, test score: 0.6774458683556731\n",
      "sub sample :: train score: 1.0, test score: 0.6970225928967511\n",
      "sub sample :: train score: 1.0, test score: 0.5963759316588455\n",
      "the mean result is: 21.736842105263158\n",
      "the score of forest is: 0.763965043256427\n"
     ]
    }
   ],
   "source": [
    "tree_num = 4\n",
    "predicates = []\n",
    "for _ in range(tree_num):\n",
    "    predicated, score = random_forest(x_train, y_train, x_test, y_test)\n",
    "    predicates.append((predicated, score))\n",
    "\n",
    "predicates_value = [v for v, s in predicates]\n",
    "forest_scores = [s for v, s in predicates]\n",
    "\n",
    "print('the mean result is: {}'.format(np.mean(predicates_value), axis=0))\n",
    "print('the score of forest is: {}'.format(r2_score(y_test, np.mean(predicates_value, axis=0))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score of weighted forest is: 0.7656685804209508\n"
     ]
    }
   ],
   "source": [
    "weights = np.array(forest_scores) / np.sum(forest_scores)\n",
    "score_weights = np.zeros_like(np.mean(predicates_value, axis=0))\n",
    "\n",
    "for i, v in enumerate(predicates_value):\n",
    "    score_weights += v * weights[i]\n",
    "\n",
    "print('the score of weighted forest is: {}'.format(r2_score(y_test, score_weights)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![欢迎订阅：坍缩的奇点](../assets/Capture-2023-11-02-164446.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
