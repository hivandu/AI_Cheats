{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01333333, 0.01333333, 0.05072262, 0.92261071])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf = DecisionTreeClassifier()\n",
    "tree_clf.fit(x, y)\n",
    "\n",
    "tree_clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "train_x, test_x,train_y, test_y = train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "tree_clf.fit(train_x, train_y)\n",
    "\n",
    "print(tree_clf.score(train_x, train_y))\n",
    "print(tree_clf.score(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fetch_openml(name='boston', version=1, as_frame=True, return_X_y=False, parser='pandas')\n",
    "\n",
    "data = dataset['data']\n",
    "target = dataset['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whole dataset train acc: 1.0\n",
      "whole dataset test acc: 0.6402937851879762\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data, target, test_size=0.3, random_state=0)\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(x_train, y_train)\n",
    "\n",
    "print('whole dataset train acc: {}'.format(tree_reg.score(x_train, y_train)))\n",
    "print('whole dataset test acc: {}'.format(tree_reg.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(x_train, y_train, x_test, y_test, drop_n=4):\n",
    "    features_random = np.random.choice(list(x_train.columns), size=len(x_train.columns)-drop_n)\n",
    "\n",
    "    x_sample = x_train[features_random]\n",
    "    y_sample = y_train\n",
    "\n",
    "    reg = DecisionTreeRegressor()\n",
    "    reg.fit(x_sample, y_sample)\n",
    "\n",
    "    score_train = reg.score(x_sample, y_sample)\n",
    "    score_test = reg.score(x_test[features_random], y_test)\n",
    "\n",
    "    print('sub sample :: train score: {}, test score: {}'.format(score_train, score_test))\n",
    "\n",
    "    y_predicated = reg.predict(x_test[features_random])\n",
    "\n",
    "    return y_predicated, score_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub sample :: train score: 1.0, test score: 0.6155417954515938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([24.1, 25.1, 20.1,  9.6, 20.8, 25. , 22.7, 23.4, 22.6, 19.6,  7. ,\n",
       "        11.9, 14.2, 10.2, 50. , 22.5, 21.8, 32.4, 28. , 20.9, 23.1, 16.1,\n",
       "        18.5, 24.4, 22.2, 20.8, 19.4, 16.4, 33.4, 19.5, 12.6, 17.7, 24.5,\n",
       "        22.2, 22.8, 17.7, 10.2, 25.1, 14.2,  9.5, 20.4, 22.5, 22. , 14.9,\n",
       "        22. , 20.6, 19.8, 19.1, 14.4, 25. , 13.1, 22.4, 20. , 46.7, 15.6,\n",
       "        22.4, 22.2, 17.5, 25.1, 20. , 24.1, 22.2, 27.9, 46.7, 17.7, 37. ,\n",
       "        18.1, 14.5, 16.7, 22.2, 20.3, 25. , 34.9, 34.9, 25. , 10.2, 34.7,\n",
       "        23.1, 28.4, 21.8, 22.2, 19.2, 22.6, 50. , 31.5, 25. , 28.4, 11.7,\n",
       "        25. , 19.9, 22. , 11.8, 18.2, 22.5, 21.6, 28.7, 13.8, 30.1, 19. ,\n",
       "        18.5, 22.4, 20.1, 27.5, 21.2, 22.2, 18.5,  8.8, 20.8, 23.9, 25.1,\n",
       "        21.9,  9.5, 15.2,  7. , 14.5, 20. , 17.9, 18.4, 10.2, 42.3, 34.9,\n",
       "        10.2, 19.8, 21.8, 18.9, 20.5, 33.2, 22.5, 20.9, 26.6, 15.1,  9.5,\n",
       "        21.5, 19.6, 10.5, 24.5, 20. , 15.6, 24.4,  8.8, 13.3, 21.8, 28.7,\n",
       "        22.2, 23.1, 14.5, 29.1, 32.5, 13.4, 10.2, 23.9, 23.6]),\n",
       " 0.6155417954515938)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest(x_train, y_train, x_test, y_test, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_feature_names = pd.DataFrame(data)\n",
    "with_feature_names.columns = dataset['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(with_feature_names, target, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub sample :: train score: 1.0, test score: 0.21063694773920416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([24.8,  7.2, 20.6, 12.1, 22.9, 20.4, 12.7, 19. , 22.1, 23.1,  7. ,\n",
       "        13.9, 16.1, 17.9, 50. , 34.9, 19.6, 34.6, 30.1, 19.3, 24.6, 20.8,\n",
       "        19.5, 24.4, 16.2,  8.8, 14.5, 19.6, 43.8, 18.3, 14.1, 13.4, 24.7,\n",
       "        20.5, 22. , 13.1, 10.2,  6.3, 17.1, 16.1, 21.7, 16.6, 36.2, 11.7,\n",
       "        23.7, 24.2, 22.8, 24.3, 50. , 22.8, 23.8, 19.4, 20. , 41.7, 22. ,\n",
       "        18.9, 17.4, 20.9,  5. , 24.7, 20.6, 17.8, 29.6, 28.4, 12. , 24.8,\n",
       "        14.3, 23.4, 15. , 22.5, 24.6, 24.8, 22. , 37. , 26.5, 16.3, 43.8,\n",
       "        23.1, 22. , 19.4, 23.9, 18. , 11.3, 37.6, 48.8, 23.4, 22.9, 11.8,\n",
       "        27. , 19.1, 18.5,  9.6, 20.5, 34.9, 21.5, 16. , 11.9, 20.1, 16.4,\n",
       "        17.6, 23.1, 22.4, 29.8, 22.8, 28.5, 18.9, 12.1, 13.1, 22.6, 24.4,\n",
       "        29.8, 11.3, 25.3, 18.3, 17.4, 22.5, 12.7, 19.6, 13.8, 50. , 28. ,\n",
       "        11.3, 16.2, 17.5, 19.7, 21.4, 32.7, 17.6, 20.7, 32.7, 16.7, 13.3,\n",
       "        15.2, 23.8, 14.1, 34.6, 20. , 50. , 28. , 16.7, 10.2, 19.5, 29.9,\n",
       "        22.2, 24.6, 15.6, 37.3, 37.3, 15.1, 11.3, 23.8, 23.9]),\n",
       " 0.21063694773920416)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest(x_train, y_train, x_test, y_test, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub sample :: train score: 1.0, test score: 0.7437817065239453\n",
      "sub sample :: train score: 1.0, test score: 0.6108074154439198\n",
      "sub sample :: train score: 1.0, test score: 0.5480721396412969\n",
      "sub sample :: train score: 1.0, test score: 0.615563128605834\n",
      "the mean result is: 21.49342105263158\n",
      "the score of forest is: 0.7679782441332592\n"
     ]
    }
   ],
   "source": [
    "tree_num = 4\n",
    "predicates = []\n",
    "for _ in range(tree_num):\n",
    "    predicated, score = random_forest(x_train, y_train, x_test, y_test)\n",
    "    predicates.append((predicated, score))\n",
    "\n",
    "predicates_value = [v for v, s in predicates]\n",
    "forest_scores = [s for v, s in predicates]\n",
    "\n",
    "print('the mean result is: {}'.format(np.mean(predicates_value), axis=0))\n",
    "print('the score of forest is: {}'.format(r2_score(y_test, np.mean(predicates_value, axis=0))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score of weighted forest is: 0.7739309396722459\n"
     ]
    }
   ],
   "source": [
    "weights = np.array(forest_scores) / np.sum(forest_scores)\n",
    "score_weights = np.zeros_like(np.mean(predicates_value, axis=0))\n",
    "\n",
    "for i, v in enumerate(predicates_value):\n",
    "    score_weights += v * weights[i]\n",
    "\n",
    "print('the score of weighted forest is: {}'.format(r2_score(y_test, score_weights)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![欢迎订阅：坍缩的奇点](../assets/Capture-2023-11-02-164446.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
