{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. 机器学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "dataset = fetch_openml(name='boston', version=1, as_frame=True, return_X_y=False, parser='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset['data']\n",
    "target = dataset['target']\n",
    "columns = dataset['feature_names']\n",
    "\n",
    "dataframe = pd.DataFrame(data)\n",
    "dataframe.columns = columns\n",
    "dataframe['price'] = dataset['target']\n",
    "\n",
    "rm = dataframe['RM']\n",
    "lstat = dataframe['LSTAT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "greater_then_most = np.percentile(dataframe['price'], 66)\n",
    "dataframe['expensive'] = dataframe['price'].apply(lambda p: int(p > greater_then_most))\n",
    "expensive = dataframe['expensive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def model(x, w, b):\n",
    "    return logistic(np.dot(x, w.T) + b)\n",
    "\n",
    "def loss(yhat, y):\n",
    "    return -np.sum(y * np.log(yhat) + (1 - y) * np.log(1 - yhat))\n",
    "\n",
    "def partial_w(x, y, yhat):\n",
    "    return np.array([np.sum((yhat - y) * x[0]), np.sum((yhat - y) * x[1])])\n",
    "\n",
    "def partial_b(x, y, yhat):\n",
    "    return np.sum((yhat - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_to_be_train, target, loss, pw, pb):\n",
    "    w = np.random.random_sample((1, 2))\n",
    "    b = 0\n",
    "\n",
    "    learning_rate = 1e-5\n",
    "    epoch = 200\n",
    "    losses = []\n",
    "\n",
    "    history_k_b_loss = []\n",
    "\n",
    "    for i in range(epoch):\n",
    "        batch_loss = []\n",
    "        for batch in range(len(rm)):\n",
    "            index = random.choice(range(len(rm)))\n",
    "\n",
    "            x = np.array([rm[index], lstat[index]])\n",
    "            y = expensive[index]\n",
    "\n",
    "            yhat = model_to_be_train(x, w, b)\n",
    "            loss_v = loss(yhat, y)\n",
    "\n",
    "            w = w + -1 * partial_w(x, y, yhat) * learning_rate\n",
    "            b = b + -1 * partial_b(x, y, yhat) * learning_rate\n",
    "\n",
    "            batch_loss.append(loss_v)\n",
    "            history_k_b_loss.append((w, b, loss_v))\n",
    "\n",
    "        #     if batch % 100 == 0:\n",
    "        #         print('Epoch: {}, Batch: {}, loss:{}'.format(i, batch, loss_v))\n",
    "        losses.append(np.mean(batch_loss))\n",
    "    return model_to_be_train, w, b, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle write finished\n"
     ]
    }
   ],
   "source": [
    "model, w, b, losses = train(model, target, loss, partial_w, partial_b)\n",
    "\n",
    "with open('logistic_regression.model', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "with open('w.model', 'wb') as f:\n",
    "    pickle.dump(w, f)\n",
    "\n",
    "with open('b.model', 'wb') as f:\n",
    "    pickle.dump(b, f)\n",
    "\n",
    "print('pickle write finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle read finished\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('logistic_regression.model', 'rb') as f:\n",
    "    model_r = pickle.load(f)\n",
    "\n",
    "with open('w.model', 'rb') as f:\n",
    "    w_r = pickle.load(f)\n",
    "\n",
    "with open('b.model', 'rb') as f:\n",
    "    b_r = pickle.load(f)\n",
    "\n",
    "print('pickle read finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels, predicated_labels, loss_labels = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RM:5.604, LSTAT:13.98, EXPENSIVE:1, Predicated:0, loss_labels [0.07980297]\n",
      "RM:6.389, LSTAT:9.62, EXPENSIVE:1, Predicated:0, loss_labels [0.37629106]\n",
      "RM:5.572, LSTAT:14.69, EXPENSIVE:0, Predicated:0, loss_labels [0.06204338]\n",
      "RM:5.602, LSTAT:16.2, EXPENSIVE:0, Predicated:0, loss_labels [0.03747754]\n",
      "RM:5.682, LSTAT:10.21, EXPENSIVE:0, Predicated:0, loss_labels [0.2592103]\n",
      "RM:6.826, LSTAT:4.16, EXPENSIVE:1, Predicated:1, loss_labels [0.84120204]\n",
      "RM:5.841, LSTAT:11.41, EXPENSIVE:0, Predicated:0, loss_labels [0.19659366]\n",
      "RM:5.468, LSTAT:26.42, EXPENSIVE:0, Predicated:0, loss_labels [0.00091931]\n",
      "RM:5.822, LSTAT:15.03, EXPENSIVE:0, Predicated:0, loss_labels [0.06175091]\n",
      "RM:6.871, LSTAT:6.07, EXPENSIVE:1, Predicated:1, loss_labels [0.73109479]\n",
      "RM:7.267, LSTAT:6.05, EXPENSIVE:1, Predicated:1, loss_labels [0.76735762]\n",
      "RM:5.468, LSTAT:26.42, EXPENSIVE:0, Predicated:0, loss_labels [0.00091931]\n",
      "RM:6.326, LSTAT:10.97, EXPENSIVE:1, Predicated:0, loss_labels [0.26477115]\n",
      "RM:6.167, LSTAT:16.29, EXPENSIVE:0, Predicated:0, loss_labels [0.04685199]\n",
      "RM:7.831, LSTAT:4.45, EXPENSIVE:1, Predicated:1, loss_labels [0.8844143]\n",
      "RM:5.87, LSTAT:14.37, EXPENSIVE:0, Predicated:0, loss_labels [0.07866966]\n",
      "RM:6.957, LSTAT:3.53, EXPENSIVE:1, Predicated:1, loss_labels [0.87607048]\n",
      "RM:6.405, LSTAT:8.2, EXPENSIVE:0, Predicated:1, loss_labels [0.50345287]\n",
      "RM:6.081, LSTAT:14.7, EXPENSIVE:0, Predicated:0, loss_labels [0.07724944]\n",
      "RM:6.619, LSTAT:7.22, EXPENSIVE:1, Predicated:1, loss_labels [0.61477907]\n",
      "RM:6.431, LSTAT:5.08, EXPENSIVE:1, Predicated:1, loss_labels [0.75953642]\n",
      "RM:5.905, LSTAT:11.45, EXPENSIVE:0, Predicated:0, loss_labels [0.19907862]\n",
      "RM:6.794, LSTAT:6.48, EXPENSIVE:0, Predicated:1, loss_labels [0.69344738]\n",
      "RM:6.575, LSTAT:4.98, EXPENSIVE:1, Predicated:1, loss_labels [0.77796167]\n",
      "RM:6.167, LSTAT:7.51, EXPENSIVE:0, Predicated:1, loss_labels [0.5375763]\n",
      "RM:7.489, LSTAT:1.73, EXPENSIVE:1, Predicated:1, loss_labels [0.94553639]\n",
      "RM:7.686, LSTAT:3.92, EXPENSIVE:1, Predicated:1, loss_labels [0.89638984]\n",
      "RM:6.113, LSTAT:12.73, EXPENSIVE:0, Predicated:0, loss_labels [0.14735379]\n",
      "RM:6.897, LSTAT:11.38, EXPENSIVE:0, Predicated:0, loss_labels [0.28889607]\n",
      "RM:6.411, LSTAT:15.02, EXPENSIVE:0, Predicated:0, loss_labels [0.08013145]\n",
      "RM:5.608, LSTAT:12.13, EXPENSIVE:1, Predicated:0, loss_labels [0.1447226]\n",
      "RM:6.975, LSTAT:4.56, EXPENSIVE:1, Predicated:1, loss_labels [0.83105038]\n",
      "RM:5.976, LSTAT:19.01, EXPENSIVE:0, Predicated:0, loss_labels [0.01658532]\n",
      "RM:7.024, LSTAT:1.98, EXPENSIVE:1, Predicated:1, loss_labels [0.92728185]\n",
      "RM:6.728, LSTAT:4.5, EXPENSIVE:1, Predicated:1, loss_labels [0.81737371]\n",
      "RM:7.61, LSTAT:3.11, EXPENSIVE:1, Predicated:1, loss_labels [0.91787873]\n",
      "RM:6.854, LSTAT:2.98, EXPENSIVE:1, Predicated:1, loss_labels [0.89143658]\n",
      "RM:6.485, LSTAT:18.85, EXPENSIVE:0, Predicated:0, loss_labels [0.02218915]\n",
      "RM:6.169, LSTAT:5.81, EXPENSIVE:1, Predicated:1, loss_labels [0.68222711]\n",
      "RM:6.43, LSTAT:5.21, EXPENSIVE:1, Predicated:1, loss_labels [0.75079032]\n",
      "RM:5.67, LSTAT:17.6, EXPENSIVE:0, Predicated:0, loss_labels [0.02370046]\n",
      "RM:6.563, LSTAT:5.68, EXPENSIVE:1, Predicated:1, loss_labels [0.73026834]\n",
      "RM:6.411, LSTAT:15.02, EXPENSIVE:0, Predicated:0, loss_labels [0.08013145]\n",
      "RM:8.297, LSTAT:7.44, EXPENSIVE:1, Predicated:1, loss_labels [0.76433404]\n",
      "RM:5.79, LSTAT:15.84, EXPENSIVE:0, Predicated:0, loss_labels [0.04618659]\n",
      "RM:8.034, LSTAT:2.88, EXPENSIVE:1, Predicated:1, loss_labels [0.93678734]\n",
      "RM:6.065, LSTAT:5.52, EXPENSIVE:0, Predicated:1, loss_labels [0.6941612]\n",
      "RM:6.516, LSTAT:6.36, EXPENSIVE:0, Predicated:1, loss_labels [0.67456445]\n",
      "RM:7.765, LSTAT:7.56, EXPENSIVE:1, Predicated:1, loss_labels [0.70752513]\n",
      "RM:6.153, LSTAT:13.15, EXPENSIVE:1, Predicated:0, loss_labels [0.13146844]\n",
      "RM:5.762, LSTAT:10.42, EXPENSIVE:0, Predicated:0, loss_labels [0.25196672]\n",
      "RM:5.95, LSTAT:27.71, EXPENSIVE:0, Predicated:0, loss_labels [0.00072452]\n",
      "RM:7.088, LSTAT:7.85, EXPENSIVE:1, Predicated:1, loss_labels [0.61320901]\n",
      "RM:5.0, LSTAT:31.99, EXPENSIVE:0, Predicated:0, loss_labels [9.92588913e-05]\n",
      "RM:6.23, LSTAT:12.93, EXPENSIVE:0, Predicated:0, loss_labels [0.14521999]\n",
      "RM:7.853, LSTAT:3.81, EXPENSIVE:1, Predicated:1, loss_labels [0.90685601]\n",
      "RM:6.442, LSTAT:8.16, EXPENSIVE:0, Predicated:1, loss_labels [0.51139998]\n",
      "RM:6.957, LSTAT:3.53, EXPENSIVE:1, Predicated:1, loss_labels [0.87607048]\n",
      "RM:6.376, LSTAT:6.87, EXPENSIVE:0, Predicated:1, loss_labels [0.61760022]\n",
      "RM:6.209, LSTAT:13.22, EXPENSIVE:0, Predicated:0, loss_labels [0.13159308]\n",
      "RM:6.216, LSTAT:9.53, EXPENSIVE:1, Predicated:0, loss_labels [0.36489549]\n",
      "RM:5.85, LSTAT:8.77, EXPENSIVE:0, Predicated:0, loss_labels [0.38880896]\n",
      "RM:5.868, LSTAT:9.97, EXPENSIVE:0, Predicated:0, loss_labels [0.29396276]\n",
      "RM:6.471, LSTAT:17.12, EXPENSIVE:0, Predicated:0, loss_labels [0.0403497]\n",
      "RM:6.406, LSTAT:19.52, EXPENSIVE:0, Predicated:0, loss_labels [0.01688622]\n",
      "RM:6.245, LSTAT:7.54, EXPENSIVE:0, Predicated:1, loss_labels [0.5439931]\n",
      "RM:5.889, LSTAT:15.71, EXPENSIVE:0, Predicated:0, loss_labels [0.05047779]\n",
      "RM:6.406, LSTAT:19.52, EXPENSIVE:0, Predicated:0, loss_labels [0.01688622]\n",
      "RM:6.358, LSTAT:11.22, EXPENSIVE:0, Predicated:0, loss_labels [0.2504237]\n",
      "RM:6.649, LSTAT:23.24, EXPENSIVE:0, Predicated:0, loss_labels [0.00501477]\n",
      "RM:5.905, LSTAT:11.45, EXPENSIVE:0, Predicated:0, loss_labels [0.19907862]\n",
      "RM:7.313, LSTAT:13.44, EXPENSIVE:0, Predicated:0, loss_labels [0.19038722]\n",
      "RM:8.375, LSTAT:3.32, EXPENSIVE:1, Predicated:1, loss_labels [0.93688735]\n",
      "RM:5.856, LSTAT:13.0, EXPENSIVE:0, Predicated:0, loss_labels [0.12200931]\n",
      "RM:6.167, LSTAT:12.33, EXPENSIVE:0, Predicated:0, loss_labels [0.16994466]\n",
      "RM:6.474, LSTAT:12.27, EXPENSIVE:0, Predicated:0, loss_labels [0.1946368]\n",
      "RM:7.686, LSTAT:3.92, EXPENSIVE:1, Predicated:1, loss_labels [0.89638984]\n",
      "RM:6.376, LSTAT:6.87, EXPENSIVE:0, Predicated:1, loss_labels [0.61760022]\n",
      "RM:6.619, LSTAT:7.22, EXPENSIVE:1, Predicated:1, loss_labels [0.61477907]\n",
      "RM:6.027, LSTAT:14.33, EXPENSIVE:0, Predicated:0, loss_labels [0.08530302]\n",
      "RM:5.854, LSTAT:23.79, EXPENSIVE:0, Predicated:0, loss_labels [0.00283738]\n",
      "RM:6.758, LSTAT:3.53, EXPENSIVE:1, Predicated:1, loss_labels [0.86555707]\n",
      "RM:6.315, LSTAT:6.29, EXPENSIVE:1, Predicated:1, loss_labels [0.65918927]\n",
      "RM:6.431, LSTAT:5.08, EXPENSIVE:1, Predicated:1, loss_labels [0.75953642]\n",
      "RM:6.096, LSTAT:10.26, EXPENSIVE:0, Predicated:0, loss_labels [0.29451119]\n",
      "RM:6.649, LSTAT:23.24, EXPENSIVE:0, Predicated:0, loss_labels [0.00501477]\n",
      "RM:6.208, LSTAT:15.17, EXPENSIVE:0, Predicated:0, loss_labels [0.06978571]\n",
      "RM:6.398, LSTAT:7.79, EXPENSIVE:1, Predicated:1, loss_labels [0.5394783]\n",
      "RM:5.985, LSTAT:9.74, EXPENSIVE:0, Predicated:0, loss_labels [0.32335954]\n",
      "RM:6.98, LSTAT:11.66, EXPENSIVE:1, Predicated:0, loss_labels [0.27635076]\n",
      "RM:6.436, LSTAT:16.22, EXPENSIVE:0, Predicated:0, loss_labels [0.05410695]\n",
      "RM:6.13, LSTAT:27.8, EXPENSIVE:0, Predicated:0, loss_labels [0.00076328]\n",
      "RM:6.301, LSTAT:16.23, EXPENSIVE:0, Predicated:0, loss_labels [0.05077704]\n",
      "RM:5.875, LSTAT:8.88, EXPENSIVE:1, Predicated:0, loss_labels [0.38220316]\n",
      "RM:5.304, LSTAT:26.64, EXPENSIVE:0, Predicated:0, loss_labels [0.00078638]\n",
      "RM:6.495, LSTAT:8.67, EXPENSIVE:1, Predicated:0, loss_labels [0.47172042]\n",
      "RM:6.019, LSTAT:12.92, EXPENSIVE:0, Predicated:0, loss_labels [0.13375828]\n",
      "RM:5.304, LSTAT:24.91, EXPENSIVE:0, Predicated:0, loss_labels [0.00146567]\n",
      "RM:4.138, LSTAT:37.97, EXPENSIVE:0, Predicated:0, loss_labels [7.67727725e-06]\n",
      "RM:5.682, LSTAT:10.21, EXPENSIVE:0, Predicated:0, loss_labels [0.2592103]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z4/ytcxq0ps02v3py23b74t70kh0000gn/T/ipykernel_26750/2755839443.py:8: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  predicate_label = int(predicate > decision_boundary)\n"
     ]
    }
   ],
   "source": [
    "random_test_indices = np.random.choice(range(len(rm)), size=100)\n",
    "decision_boundary = 0.5\n",
    "\n",
    "for i in random_test_indices:\n",
    "    x1, x2, y = rm[i], lstat[i], expensive[i]\n",
    "    predicate = model_r(np.array([x1, x2]), w_r, b_r)\n",
    "    loss_labels.append(predicate)\n",
    "    predicate_label = int(predicate > decision_boundary)\n",
    "\n",
    "    print('RM:{}, LSTAT:{}, EXPENSIVE:{}, Predicated:{}, loss_labels'.format(x1, x2, y, predicate_label), predicate)\n",
    "\n",
    "    true_labels.append(y)\n",
    "    predicated_labels.append(predicate_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(ytrues, yhats):\n",
    "    return sum(1 for yt, y1 in zip(ytrues, yhats) if yt == y1) / len(ytrues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(true_labels, predicated_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(ytrues, yhats):\n",
    "    # 预测标签是 1 的里面，正确的比例是多少\n",
    "\n",
    "    positives_pred = [y for y in yhats if y == 1]\n",
    "    return sum(1 for yt, y in zip(ytrues, yhats) if yt == y and y == 1) / len(positives_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.775"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision(true_labels, predicated_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(ytrues, yhats):\n",
    "    \n",
    "    true_positive = [y for y in ytrues if y == 1]     \n",
    "    return sum(1 for yt, y in zip(ytrues, yhats) if yt == y and yt == 1) / len(true_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.775"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(true_labels, predicated_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = [0] * 90 + [1] * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0] * 100\n",
    "b = [1] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(people, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mZeroDivisionError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mprecision\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpeople\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mprecision\u001b[39m\u001b[34m(ytrues, yhats)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprecision\u001b[39m(ytrues, yhats):\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# 预测标签是 1 的里面，正确的比例是多少\u001b[39;00m\n\u001b[32m      4\u001b[39m     positives_pred = [y \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m yhats \u001b[38;5;28;01mif\u001b[39;00m y == \u001b[32m1\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43myt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mytrues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myhats\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43myt\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpositives_pred\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mZeroDivisionError\u001b[39m: division by zero"
     ]
    }
   ],
   "source": [
    "precision(people, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(people, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(people, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision(people, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(people, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_model = [true_labels, predicated_labels, loss_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('boston_labels', 'wb') as f:\n",
    "    pickle.dump(boston_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loss_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(true_labels), len(predicated_labels), len(loss_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![欢迎订阅：坍缩的奇点](../assets/Capture-2023-11-02-164446.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
