{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. 机器学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "dataset = fetch_openml(name='boston', version=1, as_frame=True, return_X_y=False, parser='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset['data']\n",
    "target = dataset['target']\n",
    "columns = dataset['feature_names']\n",
    "\n",
    "dataframe = pd.DataFrame(data)\n",
    "dataframe.columns = columns\n",
    "dataframe['price'] = dataset['target']\n",
    "\n",
    "rm = dataframe['RM']\n",
    "lstat = dataframe['LSTAT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "greater_then_most = np.percentile(dataframe['price'], 66)\n",
    "dataframe['expensive'] = dataframe['price'].apply(lambda p: int(p > greater_then_most))\n",
    "expensive = dataframe['expensive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def model(x, w, b):\n",
    "    return logistic(np.dot(x, w.T) + b)\n",
    "\n",
    "def loss(yhat, y):\n",
    "    return -np.sum(y * np.log(yhat) + (1 - y) * np.log(1 - yhat))\n",
    "\n",
    "def partial_w(x, y, yhat):\n",
    "    return np.array([np.sum((yhat - y) * x[0]), np.sum((yhat - y) * x[1])])\n",
    "\n",
    "def partial_b(x, y, yhat):\n",
    "    return np.sum((yhat - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_to_be_train, target, loss, pw, pb):\n",
    "    w = np.random.random_sample((1, 2))\n",
    "    b = 0\n",
    "\n",
    "    learning_rate = 1e-5\n",
    "    epoch = 200\n",
    "    losses = []\n",
    "\n",
    "    history_k_b_loss = []\n",
    "\n",
    "    for i in range(epoch):\n",
    "        batch_loss = []\n",
    "        for batch in range(len(rm)):\n",
    "            index = random.choice(range(len(rm)))\n",
    "\n",
    "            x = np.array([rm[index], lstat[index]])\n",
    "            y = expensive[index]\n",
    "\n",
    "            yhat = model_to_be_train(x, w, b)\n",
    "            loss_v = loss(yhat, y)\n",
    "\n",
    "            w = w + -1 * partial_w(x, y, yhat) * learning_rate\n",
    "            b = b + -1 * partial_b(x, y, yhat) * learning_rate\n",
    "\n",
    "            batch_loss.append(loss_v)\n",
    "            history_k_b_loss.append((w, b, loss_v))\n",
    "\n",
    "        #     if batch % 100 == 0:\n",
    "        #         print('Epoch: {}, Batch: {}, loss:{}'.format(i, batch, loss_v))\n",
    "        losses.append(np.mean(batch_loss))\n",
    "    return model_to_be_train, w, b, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle write finished\n"
     ]
    }
   ],
   "source": [
    "model, w, b, losses = train(model, target, loss, partial_w, partial_b)\n",
    "\n",
    "with open('logistic_regression.model', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "with open('w.model', 'wb') as f:\n",
    "    pickle.dump(w, f)\n",
    "\n",
    "with open('b.model', 'wb') as f:\n",
    "    pickle.dump(b, f)\n",
    "\n",
    "print('pickle write finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle read finished\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('logistic_regression.model', 'rb') as f:\n",
    "    model_r = pickle.load(f)\n",
    "\n",
    "with open('w.model', 'rb') as f:\n",
    "    w_r = pickle.load(f)\n",
    "\n",
    "with open('b.model', 'rb') as f:\n",
    "    b_r = pickle.load(f)\n",
    "\n",
    "print('pickle read finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels, predicated_labels, loss_labels = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RM:4.97, LSTAT:3.26, EXPENSIVE:1, Predicated:1, loss_labels [0.71280115]\n",
      "RM:4.903, LSTAT:29.29, EXPENSIVE:0, Predicated:0, loss_labels [0.00089803]\n",
      "RM:6.635, LSTAT:5.99, EXPENSIVE:1, Predicated:1, loss_labels [0.67309195]\n",
      "RM:6.635, LSTAT:5.99, EXPENSIVE:1, Predicated:1, loss_labels [0.67309195]\n",
      "RM:8.704, LSTAT:5.12, EXPENSIVE:1, Predicated:1, loss_labels [0.85610186]\n",
      "RM:6.38, LSTAT:23.69, EXPENSIVE:0, Predicated:0, loss_labels [0.00860896]\n",
      "RM:6.482, LSTAT:7.19, EXPENSIVE:1, Predicated:1, loss_labels [0.57423992]\n",
      "RM:6.153, LSTAT:13.15, EXPENSIVE:1, Predicated:0, loss_labels [0.16302723]\n",
      "RM:5.85, LSTAT:8.77, EXPENSIVE:0, Predicated:0, loss_labels [0.39563235]\n",
      "RM:7.007, LSTAT:5.5, EXPENSIVE:1, Predicated:1, loss_labels [0.73383951]\n",
      "RM:6.593, LSTAT:9.67, EXPENSIVE:0, Predicated:0, loss_labels [0.39879034]\n",
      "RM:5.961, LSTAT:9.88, EXPENSIVE:0, Predicated:0, loss_labels [0.32789702]\n",
      "RM:6.108, LSTAT:6.57, EXPENSIVE:0, Predicated:1, loss_labels [0.58496574]\n",
      "RM:5.822, LSTAT:15.03, EXPENSIVE:0, Predicated:0, loss_labels [0.08836217]\n",
      "RM:7.853, LSTAT:3.81, EXPENSIVE:1, Predicated:1, loss_labels [0.86446505]\n",
      "RM:5.093, LSTAT:29.68, EXPENSIVE:0, Predicated:0, loss_labels [0.00085844]\n",
      "RM:5.807, LSTAT:16.03, EXPENSIVE:0, Predicated:0, loss_labels [0.06642284]\n",
      "RM:5.67, LSTAT:17.6, EXPENSIVE:0, Predicated:0, loss_labels [0.04022887]\n",
      "RM:6.096, LSTAT:10.26, EXPENSIVE:0, Predicated:0, loss_labels [0.31410555]\n",
      "RM:6.98, LSTAT:5.04, EXPENSIVE:1, Predicated:1, loss_labels [0.75829506]\n",
      "RM:5.605, LSTAT:18.46, EXPENSIVE:0, Predicated:0, loss_labels [0.0305288]\n",
      "RM:7.686, LSTAT:3.92, EXPENSIVE:1, Predicated:1, loss_labels [0.85260334]\n",
      "RM:6.495, LSTAT:12.8, EXPENSIVE:0, Predicated:0, loss_labels [0.1981462]\n",
      "RM:5.786, LSTAT:14.15, EXPENSIVE:0, Predicated:0, loss_labels [0.11098961]\n",
      "RM:5.412, LSTAT:29.55, EXPENSIVE:1, Predicated:0, loss_labels [0.00100959]\n",
      "RM:6.854, LSTAT:2.98, EXPENSIVE:1, Predicated:1, loss_labels [0.8481063]\n",
      "RM:5.404, LSTAT:23.98, EXPENSIVE:0, Predicated:0, loss_labels [0.00543031]\n",
      "RM:7.686, LSTAT:3.92, EXPENSIVE:1, Predicated:1, loss_labels [0.85260334]\n",
      "RM:6.824, LSTAT:22.74, EXPENSIVE:0, Predicated:0, loss_labels [0.01355955]\n",
      "RM:6.406, LSTAT:19.52, EXPENSIVE:0, Predicated:0, loss_labels [0.03014609]\n",
      "RM:6.273, LSTAT:6.78, EXPENSIVE:1, Predicated:1, loss_labels [0.58493033]\n",
      "RM:6.833, LSTAT:19.69, EXPENSIVE:0, Predicated:0, loss_labels [0.03362898]\n",
      "RM:6.674, LSTAT:11.98, EXPENSIVE:0, Predicated:0, loss_labels [0.25347455]\n",
      "RM:6.86, LSTAT:6.92, EXPENSIVE:1, Predicated:1, loss_labels [0.62871818]\n",
      "RM:6.12, LSTAT:9.08, EXPENSIVE:0, Predicated:0, loss_labels [0.39801793]\n",
      "RM:6.728, LSTAT:18.71, EXPENSIVE:0, Predicated:0, loss_labels [0.04305465]\n",
      "RM:6.794, LSTAT:6.48, EXPENSIVE:0, Predicated:1, loss_labels [0.65357528]\n",
      "RM:5.593, LSTAT:12.5, EXPENSIVE:0, Predicated:0, loss_labels [0.16051368]\n",
      "RM:5.412, LSTAT:29.55, EXPENSIVE:1, Predicated:0, loss_labels [0.00100959]\n",
      "RM:6.852, LSTAT:19.78, EXPENSIVE:1, Predicated:0, loss_labels [0.03298548]\n",
      "RM:5.87, LSTAT:14.37, EXPENSIVE:0, Predicated:0, loss_labels [0.10764177]\n",
      "RM:5.708, LSTAT:11.74, EXPENSIVE:0, Predicated:0, loss_labels [0.20108649]\n",
      "RM:6.027, LSTAT:14.33, EXPENSIVE:0, Predicated:0, loss_labels [0.11481895]\n",
      "RM:6.642, LSTAT:9.69, EXPENSIVE:1, Predicated:0, loss_labels [0.40186557]\n",
      "RM:6.431, LSTAT:5.08, EXPENSIVE:1, Predicated:1, loss_labels [0.71498236]\n",
      "RM:6.696, LSTAT:7.18, EXPENSIVE:1, Predicated:1, loss_labels [0.59499476]\n",
      "RM:8.704, LSTAT:5.12, EXPENSIVE:1, Predicated:1, loss_labels [0.85610186]\n",
      "RM:6.657, LSTAT:21.22, EXPENSIVE:0, Predicated:0, loss_labels [0.02003225]\n",
      "RM:5.536, LSTAT:23.6, EXPENSIVE:0, Predicated:0, loss_labels [0.00640555]\n",
      "RM:6.341, LSTAT:17.79, EXPENSIVE:0, Predicated:0, loss_labels [0.04874209]\n",
      "RM:6.254, LSTAT:10.45, EXPENSIVE:0, Predicated:0, loss_labels [0.31480085]\n",
      "RM:6.495, LSTAT:8.67, EXPENSIVE:1, Predicated:0, loss_labels [0.46384837]\n",
      "RM:7.185, LSTAT:5.39, EXPENSIVE:1, Predicated:1, loss_labels [0.75327258]\n",
      "RM:8.725, LSTAT:4.63, EXPENSIVE:1, Predicated:1, loss_labels [0.87435683]\n",
      "RM:6.152, LSTAT:26.45, EXPENSIVE:0, Predicated:0, loss_labels [0.00343074]\n",
      "RM:7.42, LSTAT:6.47, EXPENSIVE:1, Predicated:1, loss_labels [0.70661572]\n",
      "RM:6.968, LSTAT:4.59, EXPENSIVE:1, Predicated:1, loss_labels [0.78164249]\n",
      "RM:6.302, LSTAT:6.72, EXPENSIVE:1, Predicated:1, loss_labels [0.59204443]\n",
      "RM:5.87, LSTAT:14.37, EXPENSIVE:0, Predicated:0, loss_labels [0.10764177]\n",
      "RM:5.454, LSTAT:18.06, EXPENSIVE:0, Predicated:0, loss_labels [0.03245543]\n",
      "RM:6.404, LSTAT:20.31, EXPENSIVE:0, Predicated:0, loss_labels [0.02385656]\n",
      "RM:6.003, LSTAT:21.32, EXPENSIVE:0, Predicated:0, loss_labels [0.01517998]\n",
      "RM:6.096, LSTAT:20.34, EXPENSIVE:0, Predicated:0, loss_labels [0.02105546]\n",
      "RM:5.404, LSTAT:13.28, EXPENSIVE:0, Predicated:0, loss_labels [0.12304751]\n",
      "RM:6.358, LSTAT:11.22, EXPENSIVE:0, Predicated:0, loss_labels [0.27461684]\n",
      "RM:6.897, LSTAT:11.38, EXPENSIVE:0, Predicated:0, loss_labels [0.30742002]\n",
      "RM:6.182, LSTAT:9.47, EXPENSIVE:1, Predicated:0, loss_labels [0.37562218]\n",
      "RM:6.113, LSTAT:12.73, EXPENSIVE:0, Predicated:0, loss_labels [0.17889455]\n",
      "RM:8.375, LSTAT:3.32, EXPENSIVE:1, Predicated:1, loss_labels [0.90048806]\n",
      "RM:5.935, LSTAT:34.02, EXPENSIVE:0, Predicated:0, loss_labels [0.00031839]\n",
      "RM:6.081, LSTAT:14.7, EXPENSIVE:0, Predicated:0, loss_labels [0.10584617]\n",
      "RM:5.427, LSTAT:18.14, EXPENSIVE:0, Predicated:0, loss_labels [0.03138405]\n",
      "RM:6.095, LSTAT:12.4, EXPENSIVE:0, Predicated:0, loss_labels [0.1929949]\n",
      "RM:5.968, LSTAT:9.29, EXPENSIVE:0, Predicated:0, loss_labels [0.36911711]\n",
      "RM:6.416, LSTAT:9.04, EXPENSIVE:1, Predicated:0, loss_labels [0.42860249]\n",
      "RM:5.663, LSTAT:8.05, EXPENSIVE:0, Predicated:0, loss_labels [0.43111807]\n",
      "RM:6.169, LSTAT:5.81, EXPENSIVE:1, Predicated:1, loss_labels [0.64503404]\n",
      "RM:6.552, LSTAT:3.76, EXPENSIVE:1, Predicated:1, loss_labels [0.79686565]\n",
      "RM:6.436, LSTAT:16.22, EXPENSIVE:0, Predicated:0, loss_labels [0.07883397]\n",
      "RM:7.52, LSTAT:7.26, EXPENSIVE:1, Predicated:1, loss_labels [0.66325659]\n",
      "RM:6.279, LSTAT:11.97, EXPENSIVE:0, Predicated:0, loss_labels [0.2263017]\n",
      "RM:6.333, LSTAT:7.34, EXPENSIVE:0, Predicated:1, loss_labels [0.54890706]\n",
      "RM:5.966, LSTAT:14.44, EXPENSIVE:0, Predicated:0, loss_labels [0.10916376]\n",
      "RM:6.004, LSTAT:14.27, EXPENSIVE:0, Predicated:0, loss_labels [0.11577197]\n",
      "RM:5.936, LSTAT:5.57, EXPENSIVE:0, Predicated:1, loss_labels [0.64114357]\n",
      "RM:6.114, LSTAT:14.98, EXPENSIVE:0, Predicated:0, loss_labels [0.09920132]\n",
      "RM:8.375, LSTAT:3.32, EXPENSIVE:1, Predicated:1, loss_labels [0.90048806]\n",
      "RM:6.108, LSTAT:6.57, EXPENSIVE:0, Predicated:1, loss_labels [0.58496574]\n",
      "RM:6.185, LSTAT:18.13, EXPENSIVE:0, Predicated:0, loss_labels [0.04170632]\n",
      "RM:5.604, LSTAT:13.98, EXPENSIVE:1, Predicated:0, loss_labels [0.10917342]\n",
      "RM:7.489, LSTAT:1.73, EXPENSIVE:1, Predicated:1, loss_labels [0.91243424]\n",
      "RM:5.936, LSTAT:5.57, EXPENSIVE:0, Predicated:1, loss_labels [0.64114357]\n",
      "RM:6.794, LSTAT:6.48, EXPENSIVE:0, Predicated:1, loss_labels [0.65357528]\n",
      "RM:6.417, LSTAT:8.81, EXPENSIVE:0, Predicated:0, loss_labels [0.4458663]\n",
      "RM:7.875, LSTAT:2.97, EXPENSIVE:1, Predicated:1, loss_labels [0.89246944]\n",
      "RM:6.575, LSTAT:4.98, EXPENSIVE:1, Predicated:1, loss_labels [0.73214363]\n",
      "RM:6.402, LSTAT:11.32, EXPENSIVE:0, Predicated:0, loss_labels [0.27195784]\n",
      "RM:6.279, LSTAT:11.97, EXPENSIVE:0, Predicated:0, loss_labels [0.2263017]\n",
      "RM:5.693, LSTAT:17.19, EXPENSIVE:0, Predicated:0, loss_labels [0.04570118]\n",
      "RM:7.241, LSTAT:5.49, EXPENSIVE:1, Predicated:1, loss_labels [0.75163988]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h4/7cr1cmpn7v5b3x20_9wz8m740000gn/T/ipykernel_65252/2755839443.py:8: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  predicate_label = int(predicate > decision_boundary)\n"
     ]
    }
   ],
   "source": [
    "random_test_indices = np.random.choice(range(len(rm)), size=100)\n",
    "decision_boundary = 0.5\n",
    "\n",
    "for i in random_test_indices:\n",
    "    x1, x2, y = rm[i], lstat[i], expensive[i]\n",
    "    predicate = model_r(np.array([x1, x2]), w_r, b_r)\n",
    "    loss_labels.append(predicate)\n",
    "    predicate_label = int(predicate > decision_boundary)\n",
    "\n",
    "    print('RM:{}, LSTAT:{}, EXPENSIVE:{}, Predicated:{}, loss_labels'.format(x1, x2, y, predicate_label), predicate)\n",
    "\n",
    "    true_labels.append(y)\n",
    "    predicated_labels.append(predicate_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(ytrues, yhats):\n",
    "    return sum(1 for yt, y1 in zip(ytrues, yhats) if yt == y1) / len(ytrues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(true_labels, predicated_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(ytrues, yhats):\n",
    "    # 预测标签是 1 的里面，正确的比例是多少\n",
    "\n",
    "    positives_pred = [y for y in yhats if y == 1]\n",
    "    if len(positives_pred) == 0:\n",
    "        return 0.0\n",
    "    return sum(1 for yt, y in zip(ytrues, yhats) if yt == y and y == 1) / len(positives_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8108108108108109"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision(true_labels, predicated_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(ytrues, yhats):\n",
    "    \n",
    "    true_positive = [y for y in ytrues if y == 1]     \n",
    "    return sum(1 for yt, y in zip(ytrues, yhats) if yt == y and yt == 1) / len(true_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7692307692307693"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(true_labels, predicated_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = [0] * 90 + [1] * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0] * 100\n",
    "b = [1] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(people, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision(people, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(people, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(people, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision(people, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(people, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_model = [true_labels, predicated_labels, loss_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('boston_labels', 'wb') as f:\n",
    "    pickle.dump(boston_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loss_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(true_labels), len(predicated_labels), len(loss_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![欢迎订阅：坍缩的奇点](../assets/Capture-2023-11-02-164446.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
