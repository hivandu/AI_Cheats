{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. 机器学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "dataset = fetch_openml(name='boston', version=1, as_frame=True, return_X_y=False, parser='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset['data']\n",
    "target = dataset['target']\n",
    "columns = dataset['feature_names']\n",
    "\n",
    "dataframe = pd.DataFrame(data)\n",
    "dataframe.columns = columns\n",
    "dataframe['price'] = dataset['target']\n",
    "\n",
    "rm = dataframe['RM']\n",
    "lstat = dataframe['LSTAT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "greater_then_most = np.percentile(dataframe['price'], 66)\n",
    "dataframe['expensive'] = dataframe['price'].apply(lambda p: int(p > greater_then_most))\n",
    "expensive = dataframe['expensive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def model(x, w, b):\n",
    "    return logistic(np.dot(x, w.T) + b)\n",
    "\n",
    "def loss(yhat, y):\n",
    "    return -np.sum(y * np.log(yhat) + (1 - y) * np.log(1 - yhat))\n",
    "\n",
    "def partial_w(x, y, yhat):\n",
    "    return np.array([np.sum((yhat - y) * x[0]), np.sum((yhat - y) * x[1])])\n",
    "\n",
    "def partial_b(x, y, yhat):\n",
    "    return np.sum((yhat - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_to_be_train, target, loss, pw, pb):\n",
    "    w = np.random.random_sample((1, 2))\n",
    "    b = 0\n",
    "\n",
    "    learning_rate = 1e-5\n",
    "    epoch = 200\n",
    "    losses = []\n",
    "\n",
    "    history_k_b_loss = []\n",
    "\n",
    "    for i in range(epoch):\n",
    "        batch_loss = []\n",
    "        for batch in range(len(rm)):\n",
    "            index = random.choice(range(len(rm)))\n",
    "\n",
    "            x = np.array([rm[index], lstat[index]])\n",
    "            y = expensive[index]\n",
    "\n",
    "            yhat = model_to_be_train(x, w, b)\n",
    "            loss_v = loss(yhat, y)\n",
    "\n",
    "            w = w + -1 * partial_w(x, y, yhat) * learning_rate\n",
    "            b = b + -1 * partial_b(x, y, yhat) * learning_rate\n",
    "\n",
    "            batch_loss.append(loss_v)\n",
    "            history_k_b_loss.append((w, b, loss_v))\n",
    "\n",
    "        #     if batch % 100 == 0:\n",
    "        #         print('Epoch: {}, Batch: {}, loss:{}'.format(i, batch, loss_v))\n",
    "        losses.append(np.mean(batch_loss))\n",
    "    return model_to_be_train, w, b, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle write finished\n"
     ]
    }
   ],
   "source": [
    "model, w, b, losses = train(model, target, loss, partial_w, partial_b)\n",
    "\n",
    "with open('logistic_regression.model', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "with open('w.model', 'wb') as f:\n",
    "    pickle.dump(w, f)\n",
    "\n",
    "with open('b.model', 'wb') as f:\n",
    "    pickle.dump(b, f)\n",
    "\n",
    "print('pickle write finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle read finished\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('logistic_regression.model', 'rb') as f:\n",
    "    model_r = pickle.load(f)\n",
    "\n",
    "with open('w.model', 'rb') as f:\n",
    "    w_r = pickle.load(f)\n",
    "\n",
    "with open('b.model', 'rb') as f:\n",
    "    b_r = pickle.load(f)\n",
    "\n",
    "print('pickle read finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels, predicated_labels, loss_labels = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RM:5.747, LSTAT:19.92, EXPENSIVE:0, Predicated:0, loss_labels [0.00982901]\n",
      "RM:5.887, LSTAT:16.35, EXPENSIVE:0, Predicated:0, loss_labels [0.03827239]\n",
      "RM:6.302, LSTAT:6.72, EXPENSIVE:1, Predicated:1, loss_labels [0.6317575]\n",
      "RM:6.545, LSTAT:21.08, EXPENSIVE:0, Predicated:0, loss_labels [0.00944896]\n",
      "RM:8.725, LSTAT:4.63, EXPENSIVE:1, Predicated:1, loss_labels [0.92374536]\n",
      "RM:6.312, LSTAT:10.58, EXPENSIVE:0, Predicated:0, loss_labels [0.2925838]\n",
      "RM:5.52, LSTAT:24.56, EXPENSIVE:0, Predicated:0, loss_labels [0.00159511]\n",
      "RM:5.913, LSTAT:16.21, EXPENSIVE:0, Predicated:0, loss_labels [0.04071672]\n",
      "RM:5.399, LSTAT:30.81, EXPENSIVE:0, Predicated:0, loss_labels [0.00014927]\n",
      "RM:6.137, LSTAT:13.44, EXPENSIVE:0, Predicated:0, loss_labels [0.11651015]\n",
      "RM:6.38, LSTAT:23.69, EXPENSIVE:0, Predicated:0, loss_labels [0.00334127]\n",
      "RM:5.926, LSTAT:13.59, EXPENSIVE:1, Predicated:0, loss_labels [0.10117135]\n",
      "RM:5.854, LSTAT:23.79, EXPENSIVE:0, Predicated:0, loss_labels [0.00249352]\n",
      "RM:6.485, LSTAT:18.85, EXPENSIVE:0, Predicated:0, loss_labels [0.02069568]\n",
      "RM:6.77, LSTAT:4.84, EXPENSIVE:1, Predicated:1, loss_labels [0.8120316]\n",
      "RM:6.251, LSTAT:16.44, EXPENSIVE:0, Predicated:0, loss_labels [0.04394957]\n",
      "RM:6.027, LSTAT:14.33, EXPENSIVE:0, Predicated:0, loss_labels [0.0825126]\n",
      "RM:6.343, LSTAT:20.32, EXPENSIVE:0, Predicated:0, loss_labels [0.01131993]\n",
      "RM:7.079, LSTAT:5.7, EXPENSIVE:1, Predicated:1, loss_labels [0.78514668]\n",
      "RM:6.511, LSTAT:5.28, EXPENSIVE:1, Predicated:1, loss_labels [0.76390928]\n",
      "RM:5.155, LSTAT:20.08, EXPENSIVE:0, Predicated:0, loss_labels [0.00696117]\n",
      "RM:6.108, LSTAT:9.16, EXPENSIVE:1, Predicated:0, loss_labels [0.38764773]\n",
      "RM:6.103, LSTAT:23.29, EXPENSIVE:0, Predicated:0, loss_labels [0.0033843]\n",
      "RM:5.836, LSTAT:18.66, EXPENSIVE:0, Predicated:0, loss_labels [0.01625189]\n",
      "RM:6.552, LSTAT:3.76, EXPENSIVE:1, Predicated:1, loss_labels [0.85275269]\n",
      "RM:6.232, LSTAT:12.34, EXPENSIVE:0, Predicated:0, loss_labels [0.17182215]\n",
      "RM:5.856, LSTAT:25.41, EXPENSIVE:0, Predicated:0, loss_labels [0.00137257]\n",
      "RM:6.343, LSTAT:20.32, EXPENSIVE:0, Predicated:0, loss_labels [0.01131993]\n",
      "RM:5.96, LSTAT:17.27, EXPENSIVE:0, Predicated:0, loss_labels [0.02850833]\n",
      "RM:6.326, LSTAT:10.97, EXPENSIVE:1, Predicated:0, loss_labels [0.26497469]\n",
      "RM:7.358, LSTAT:4.73, EXPENSIVE:1, Predicated:1, loss_labels [0.85701385]\n",
      "RM:6.471, LSTAT:17.12, EXPENSIVE:0, Predicated:0, loss_labels [0.03827415]\n",
      "RM:6.064, LSTAT:14.66, EXPENSIVE:1, Predicated:0, loss_labels [0.07497374]\n",
      "RM:6.538, LSTAT:7.73, EXPENSIVE:1, Predicated:1, loss_labels [0.56987451]\n",
      "RM:6.552, LSTAT:3.76, EXPENSIVE:1, Predicated:1, loss_labels [0.85275269]\n",
      "RM:7.249, LSTAT:4.81, EXPENSIVE:1, Predicated:1, loss_labels [0.84657184]\n",
      "RM:7.929, LSTAT:3.7, EXPENSIVE:1, Predicated:1, loss_labels [0.92056817]\n",
      "RM:5.957, LSTAT:20.62, EXPENSIVE:0, Predicated:0, loss_labels [0.00841741]\n",
      "RM:6.487, LSTAT:5.9, EXPENSIVE:1, Predicated:1, loss_labels [0.71773203]\n",
      "RM:5.818, LSTAT:22.11, EXPENSIVE:0, Predicated:0, loss_labels [0.00455111]\n",
      "RM:6.458, LSTAT:12.6, EXPENSIVE:0, Predicated:0, loss_labels [0.1738327]\n",
      "RM:6.249, LSTAT:10.59, EXPENSIVE:0, Predicated:0, loss_labels [0.28551027]\n",
      "RM:6.495, LSTAT:12.8, EXPENSIVE:0, Predicated:0, loss_labels [0.16594767]\n",
      "RM:6.101, LSTAT:9.81, EXPENSIVE:1, Predicated:0, loss_labels [0.33158875]\n",
      "RM:5.605, LSTAT:18.46, EXPENSIVE:0, Predicated:0, loss_labels [0.01564473]\n",
      "RM:6.273, LSTAT:6.78, EXPENSIVE:1, Predicated:1, loss_labels [0.62326546]\n",
      "RM:5.876, LSTAT:9.25, EXPENSIVE:0, Predicated:0, loss_labels [0.35351176]\n",
      "RM:6.618, LSTAT:7.6, EXPENSIVE:1, Predicated:1, loss_labels [0.59107979]\n",
      "RM:6.02, LSTAT:10.11, EXPENSIVE:0, Predicated:0, loss_labels [0.29912727]\n",
      "RM:7.163, LSTAT:6.36, EXPENSIVE:1, Predicated:1, loss_labels [0.74890842]\n",
      "RM:6.546, LSTAT:5.33, EXPENSIVE:1, Predicated:1, loss_labels [0.76365274]\n",
      "RM:5.935, LSTAT:6.58, EXPENSIVE:0, Predicated:1, loss_labels [0.60170091]\n",
      "RM:6.567, LSTAT:9.28, EXPENSIVE:1, Predicated:0, loss_labels [0.43100784]\n",
      "RM:7.185, LSTAT:4.03, EXPENSIVE:1, Predicated:1, loss_labels [0.87709579]\n",
      "RM:5.888, LSTAT:14.8, EXPENSIVE:0, Predicated:0, loss_labels [0.065971]\n",
      "RM:6.674, LSTAT:11.98, EXPENSIVE:0, Predicated:0, loss_labels [0.22722024]\n",
      "RM:6.176, LSTAT:12.04, EXPENSIVE:0, Predicated:0, loss_labels [0.18405201]\n",
      "RM:4.138, LSTAT:37.97, EXPENSIVE:0, Predicated:0, loss_labels [5.71449962e-06]\n",
      "RM:8.034, LSTAT:2.88, EXPENSIVE:1, Predicated:1, loss_labels [0.94292133]\n",
      "RM:5.857, LSTAT:21.32, EXPENSIVE:0, Predicated:0, loss_labels [0.00620212]\n",
      "RM:6.393, LSTAT:5.19, EXPENSIVE:1, Predicated:1, loss_labels [0.75950537]\n",
      "RM:4.519, LSTAT:36.98, EXPENSIVE:0, Predicated:0, loss_labels [9.92378564e-06]\n",
      "RM:5.569, LSTAT:15.1, EXPENSIVE:0, Predicated:0, loss_labels [0.05132876]\n",
      "RM:5.851, LSTAT:16.47, EXPENSIVE:0, Predicated:0, loss_labels [0.03605677]\n",
      "RM:5.759, LSTAT:14.13, EXPENSIVE:0, Predicated:0, loss_labels [0.07831791]\n",
      "RM:6.162, LSTAT:7.43, EXPENSIVE:1, Predicated:1, loss_labels [0.55203954]\n",
      "RM:6.75, LSTAT:7.74, EXPENSIVE:1, Predicated:1, loss_labels [0.59412171]\n",
      "RM:6.003, LSTAT:21.32, EXPENSIVE:0, Predicated:0, loss_labels [0.00665678]\n",
      "RM:6.129, LSTAT:15.12, EXPENSIVE:0, Predicated:0, loss_labels [0.06592111]\n",
      "RM:6.405, LSTAT:10.63, EXPENSIVE:0, Predicated:0, loss_labels [0.29817487]\n",
      "RM:5.693, LSTAT:17.19, EXPENSIVE:0, Predicated:0, loss_labels [0.02584978]\n",
      "RM:6.63, LSTAT:4.7, EXPENSIVE:1, Predicated:1, loss_labels [0.80949991]\n",
      "RM:6.113, LSTAT:12.73, EXPENSIVE:0, Predicated:0, loss_labels [0.14491753]\n",
      "RM:6.059, LSTAT:8.51, EXPENSIVE:0, Predicated:0, loss_labels [0.44010799]\n",
      "RM:6.436, LSTAT:16.22, EXPENSIVE:0, Predicated:0, loss_labels [0.05175043]\n",
      "RM:5.898, LSTAT:12.67, EXPENSIVE:0, Predicated:0, loss_labels [0.13497174]\n",
      "RM:6.249, LSTAT:10.59, EXPENSIVE:0, Predicated:0, loss_labels [0.28551027]\n",
      "RM:6.417, LSTAT:6.72, EXPENSIVE:1, Predicated:1, loss_labels [0.64470584]\n",
      "RM:6.182, LSTAT:9.47, EXPENSIVE:1, Predicated:0, loss_labels [0.369173]\n",
      "RM:7.147, LSTAT:5.33, EXPENSIVE:1, Predicated:1, loss_labels [0.81243517]\n",
      "RM:5.868, LSTAT:9.97, EXPENSIVE:0, Predicated:0, loss_labels [0.29446196]\n",
      "RM:6.701, LSTAT:16.42, EXPENSIVE:0, Predicated:0, loss_labels [0.054531]\n",
      "RM:5.762, LSTAT:10.42, EXPENSIVE:0, Predicated:0, loss_labels [0.25125592]\n",
      "RM:5.701, LSTAT:18.35, EXPENSIVE:0, Predicated:0, loss_labels [0.0170509]\n",
      "RM:7.249, LSTAT:4.81, EXPENSIVE:1, Predicated:1, loss_labels [0.84657184]\n",
      "RM:6.315, LSTAT:6.29, EXPENSIVE:1, Predicated:1, loss_labels [0.66932349]\n",
      "RM:5.682, LSTAT:10.21, EXPENSIVE:0, Predicated:0, loss_labels [0.25859616]\n",
      "RM:5.682, LSTAT:10.21, EXPENSIVE:0, Predicated:0, loss_labels [0.25859616]\n",
      "RM:6.75, LSTAT:7.74, EXPENSIVE:1, Predicated:1, loss_labels [0.59412171]\n",
      "RM:6.012, LSTAT:12.43, EXPENSIVE:0, Predicated:0, loss_labels [0.15273058]\n",
      "RM:6.461, LSTAT:18.05, EXPENSIVE:0, Predicated:0, loss_labels [0.02731126]\n",
      "RM:6.279, LSTAT:11.97, EXPENSIVE:0, Predicated:0, loss_labels [0.19575928]\n",
      "RM:8.375, LSTAT:3.32, EXPENSIVE:1, Predicated:1, loss_labels [0.94311372]\n",
      "RM:5.841, LSTAT:11.41, EXPENSIVE:0, Predicated:0, loss_labels [0.19473675]\n",
      "RM:6.417, LSTAT:8.81, EXPENSIVE:0, Predicated:0, loss_labels [0.45584588]\n",
      "RM:5.981, LSTAT:11.65, EXPENSIVE:1, Predicated:0, loss_labels [0.19154515]\n",
      "RM:5.468, LSTAT:26.42, EXPENSIVE:0, Predicated:0, loss_labels [0.00078234]\n",
      "RM:6.144, LSTAT:9.45, EXPENSIVE:1, Predicated:0, loss_labels [0.36658346]\n",
      "RM:5.427, LSTAT:18.14, EXPENSIVE:0, Predicated:0, loss_labels [0.01613785]\n",
      "RM:5.981, LSTAT:11.65, EXPENSIVE:1, Predicated:0, loss_labels [0.19154515]\n"
     ]
    }
   ],
   "source": [
    "random_test_indices = np.random.choice(range(len(rm)), size=100)\n",
    "decision_boundary = 0.5\n",
    "\n",
    "for i in random_test_indices:\n",
    "    x1, x2, y = rm[i], lstat[i], expensive[i]\n",
    "    predicate = model_r(np.array([x1, x2]), w_r, b_r)\n",
    "    loss_labels.append(predicate)\n",
    "    predicate_label = int(predicate > decision_boundary)\n",
    "\n",
    "    print('RM:{}, LSTAT:{}, EXPENSIVE:{}, Predicated:{}, loss_labels'.format(x1, x2, y, predicate_label), predicate)\n",
    "\n",
    "    true_labels.append(y)\n",
    "    predicated_labels.append(predicate_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(ytrues, yhats):\n",
    "    return sum(1 for yt, y1 in zip(ytrues, yhats) if yt == y1) / len(ytrues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(true_labels, predicated_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(ytrues, yhats):\n",
    "    # 预测标签是 1 的里面，正确的比例是多少\n",
    "\n",
    "    positives_pred = [y for y in yhats if y == 1]\n",
    "    return sum(1 for yt, y in zip(ytrues, yhats) if yt == y and y == 1) / len(positives_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9655172413793104"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision(true_labels, predicated_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(ytrues, yhats):\n",
    "    \n",
    "    true_positive = [y for y in ytrues if y == 1]     \n",
    "    return sum(1 for yt, y in zip(ytrues, yhats) if yt == y and yt == 1) / len(true_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7368421052631579"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(true_labels, predicated_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = [0] * 90 + [1] * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0] * 100\n",
    "b = [1] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(people, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprecision\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpeople\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m, in \u001b[0;36mprecision\u001b[0;34m(ytrues, yhats)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprecision\u001b[39m(ytrues, yhats):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# 预测标签是 1 的里面，正确的比例是多少\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     positives_pred \u001b[38;5;241m=\u001b[39m [y \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m yhats \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43myt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mytrues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myhats\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43myt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpositives_pred\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "precision(people, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(people, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(people, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision(people, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(people, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_model = [true_labels, predicated_labels, loss_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('boston_labels', 'wb') as f:\n",
    "    pickle.dump(boston_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loss_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(true_labels), len(predicated_labels), len(loss_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![欢迎订阅：坍缩的奇点](../assets/Capture-2023-11-02-164446.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
