{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. 机器学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "dataset = fetch_openml(name='boston', version=1, as_frame=True, return_X_y=False, parser='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset['data']\n",
    "target = dataset['target']\n",
    "columns = dataset['feature_names']\n",
    "\n",
    "dataframe = pd.DataFrame(data)\n",
    "dataframe.columns = columns\n",
    "dataframe['price'] = dataset['target']\n",
    "\n",
    "rm = dataframe['RM']\n",
    "lstat = dataframe['LSTAT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "greater_then_most = np.percentile(dataframe['price'], 66)\n",
    "dataframe['expensive'] = dataframe['price'].apply(lambda p: int(p > greater_then_most))\n",
    "expensive = dataframe['expensive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def model(x, w, b):\n",
    "    return logistic(np.dot(x, w.T) + b)\n",
    "\n",
    "def loss(yhat, y):\n",
    "    return -np.sum(y * np.log(yhat) + (1 - y) * np.log(1 - yhat))\n",
    "\n",
    "def partial_w(x, y, yhat):\n",
    "    return np.array([np.sum((yhat - y) * x[0]), np.sum((yhat - y) * x[1])])\n",
    "\n",
    "def partial_b(x, y, yhat):\n",
    "    return np.sum((yhat - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_to_be_train, target, loss, pw, pb):\n",
    "    w = np.random.random_sample((1, 2))\n",
    "    b = 0\n",
    "\n",
    "    learning_rate = 1e-5\n",
    "    epoch = 200\n",
    "    losses = []\n",
    "\n",
    "    history_k_b_loss = []\n",
    "\n",
    "    for i in range(epoch):\n",
    "        batch_loss = []\n",
    "        for batch in range(len(rm)):\n",
    "            index = random.choice(range(len(rm)))\n",
    "\n",
    "            x = np.array([rm[index], lstat[index]])\n",
    "            y = expensive[index]\n",
    "\n",
    "            yhat = model_to_be_train(x, w, b)\n",
    "            loss_v = loss(yhat, y)\n",
    "\n",
    "            w = w + -1 * partial_w(x, y, yhat) * learning_rate\n",
    "            b = b + -1 * partial_b(x, y, yhat) * learning_rate\n",
    "\n",
    "            batch_loss.append(loss_v)\n",
    "            history_k_b_loss.append((w, b, loss_v))\n",
    "\n",
    "        #     if batch % 100 == 0:\n",
    "        #         print('Epoch: {}, Batch: {}, loss:{}'.format(i, batch, loss_v))\n",
    "        losses.append(np.mean(batch_loss))\n",
    "    return model_to_be_train, w, b, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle write finished\n"
     ]
    }
   ],
   "source": [
    "model, w, b, losses = train(model, target, loss, partial_w, partial_b)\n",
    "\n",
    "with open('logistic_regression.model', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "with open('w.model', 'wb') as f:\n",
    "    pickle.dump(w, f)\n",
    "\n",
    "with open('b.model', 'wb') as f:\n",
    "    pickle.dump(b, f)\n",
    "\n",
    "print('pickle write finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle read finished\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('logistic_regression.model', 'rb') as f:\n",
    "    model_r = pickle.load(f)\n",
    "\n",
    "with open('w.model', 'rb') as f:\n",
    "    w_r = pickle.load(f)\n",
    "\n",
    "with open('b.model', 'rb') as f:\n",
    "    b_r = pickle.load(f)\n",
    "\n",
    "print('pickle read finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels, predicated_labels, loss_labels = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RM:5.707, LSTAT:12.01, EXPENSIVE:0, Predicated:0, loss_labels [0.19626449]\n",
      "RM:6.657, LSTAT:21.22, EXPENSIVE:0, Predicated:0, loss_labels [0.02528174]\n",
      "RM:5.895, LSTAT:10.56, EXPENSIVE:0, Predicated:0, loss_labels [0.28031166]\n",
      "RM:6.121, LSTAT:8.44, EXPENSIVE:0, Predicated:0, loss_labels [0.43124459]\n",
      "RM:7.333, LSTAT:7.79, EXPENSIVE:1, Predicated:1, loss_labels [0.57760506]\n",
      "RM:6.081, LSTAT:14.7, EXPENSIVE:0, Predicated:0, loss_labels [0.11586862]\n",
      "RM:4.903, LSTAT:29.29, EXPENSIVE:0, Predicated:0, loss_labels [0.00151733]\n",
      "RM:6.083, LSTAT:12.79, EXPENSIVE:0, Predicated:0, loss_labels [0.18242465]\n",
      "RM:7.61, LSTAT:3.11, EXPENSIVE:1, Predicated:1, loss_labels [0.84665844]\n",
      "RM:6.8, LSTAT:5.03, EXPENSIVE:1, Predicated:1, loss_labels [0.71118202]\n",
      "RM:7.47, LSTAT:3.16, EXPENSIVE:1, Predicated:1, loss_labels [0.83855137]\n",
      "RM:7.249, LSTAT:4.81, EXPENSIVE:1, Predicated:1, loss_labels [0.75283958]\n",
      "RM:5.841, LSTAT:11.41, EXPENSIVE:0, Predicated:0, loss_labels [0.23189355]\n",
      "RM:5.933, LSTAT:9.68, EXPENSIVE:0, Predicated:0, loss_labels [0.33509452]\n",
      "RM:6.185, LSTAT:18.03, EXPENSIVE:0, Predicated:0, loss_labels [0.05099646]\n",
      "RM:5.787, LSTAT:10.24, EXPENSIVE:0, Predicated:0, loss_labels [0.29104641]\n",
      "RM:5.741, LSTAT:13.15, EXPENSIVE:0, Predicated:0, loss_labels [0.15244539]\n",
      "RM:6.678, LSTAT:6.27, EXPENSIVE:1, Predicated:1, loss_labels [0.6259636]\n",
      "RM:6.438, LSTAT:3.59, EXPENSIVE:1, Predicated:1, loss_labels [0.76489422]\n",
      "RM:5.856, LSTAT:13.0, EXPENSIVE:0, Predicated:0, loss_labels [0.16314436]\n",
      "RM:6.219, LSTAT:16.59, EXPENSIVE:0, Predicated:0, loss_labels [0.07505601]\n",
      "RM:6.163, LSTAT:11.34, EXPENSIVE:0, Predicated:0, loss_labels [0.25548907]\n",
      "RM:8.375, LSTAT:3.32, EXPENSIVE:1, Predicated:1, loss_labels [0.87082382]\n",
      "RM:7.178, LSTAT:2.87, EXPENSIVE:1, Predicated:1, loss_labels [0.83612567]\n",
      "RM:6.031, LSTAT:7.83, EXPENSIVE:0, Predicated:0, loss_labels [0.46570396]\n",
      "RM:8.297, LSTAT:7.44, EXPENSIVE:1, Predicated:1, loss_labels [0.6760191]\n",
      "RM:6.59, LSTAT:9.5, EXPENSIVE:0, Predicated:0, loss_labels [0.39807017]\n",
      "RM:6.549, LSTAT:7.39, EXPENSIVE:1, Predicated:1, loss_labels [0.53985917]\n",
      "RM:6.129, LSTAT:15.12, EXPENSIVE:0, Predicated:0, loss_labels [0.10594723]\n",
      "RM:6.172, LSTAT:19.15, EXPENSIVE:1, Predicated:0, loss_labels [0.03769921]\n",
      "RM:5.693, LSTAT:17.19, EXPENSIVE:0, Predicated:0, loss_labels [0.05437746]\n",
      "RM:5.019, LSTAT:34.41, EXPENSIVE:0, Predicated:0, loss_labels [0.00038005]\n",
      "RM:6.145, LSTAT:6.86, EXPENSIVE:0, Predicated:1, loss_labels [0.54263745]\n",
      "RM:5.747, LSTAT:19.92, EXPENSIVE:0, Predicated:0, loss_labels [0.02666659]\n",
      "RM:5.404, LSTAT:23.98, EXPENSIVE:0, Predicated:0, loss_labels [0.00782372]\n",
      "RM:5.99, LSTAT:14.67, EXPENSIVE:0, Predicated:0, loss_labels [0.11359855]\n",
      "RM:7.236, LSTAT:6.93, EXPENSIVE:1, Predicated:1, loss_labels [0.62703721]\n",
      "RM:6.041, LSTAT:7.7, EXPENSIVE:0, Predicated:0, loss_labels [0.47555619]\n",
      "RM:6.728, LSTAT:18.71, EXPENSIVE:0, Predicated:0, loss_labels [0.05070508]\n",
      "RM:5.895, LSTAT:10.56, EXPENSIVE:0, Predicated:0, loss_labels [0.28031166]\n",
      "RM:5.272, LSTAT:16.14, EXPENSIVE:0, Predicated:0, loss_labels [0.06263512]\n",
      "RM:6.142, LSTAT:18.72, EXPENSIVE:0, Predicated:0, loss_labels [0.04188025]\n",
      "RM:5.889, LSTAT:15.71, EXPENSIVE:0, Predicated:0, loss_labels [0.08486914]\n",
      "RM:4.88, LSTAT:30.62, EXPENSIVE:0, Predicated:0, loss_labels [0.00104038]\n",
      "RM:6.245, LSTAT:7.54, EXPENSIVE:0, Predicated:1, loss_labels [0.50387127]\n",
      "RM:5.952, LSTAT:17.15, EXPENSIVE:0, Predicated:0, loss_labels [0.05967053]\n",
      "RM:5.747, LSTAT:19.92, EXPENSIVE:0, Predicated:0, loss_labels [0.02666659]\n",
      "RM:5.57, LSTAT:21.02, EXPENSIVE:0, Predicated:0, loss_labels [0.01864958]\n",
      "RM:5.924, LSTAT:16.3, EXPENSIVE:0, Predicated:0, loss_labels [0.07375976]\n",
      "RM:6.152, LSTAT:15.02, EXPENSIVE:0, Predicated:0, loss_labels [0.10936544]\n",
      "RM:6.485, LSTAT:18.85, EXPENSIVE:0, Predicated:0, loss_labels [0.04519057]\n",
      "RM:5.85, LSTAT:8.77, EXPENSIVE:0, Predicated:0, loss_labels [0.3869813]\n",
      "RM:6.794, LSTAT:6.48, EXPENSIVE:0, Predicated:1, loss_labels [0.62143348]\n",
      "RM:6.619, LSTAT:7.22, EXPENSIVE:1, Predicated:1, loss_labels [0.55741885]\n",
      "RM:6.209, LSTAT:13.22, EXPENSIVE:0, Predicated:0, loss_labels [0.1711994]\n",
      "RM:5.963, LSTAT:13.45, EXPENSIVE:0, Predicated:0, loss_labels [0.15133924]\n",
      "RM:6.315, LSTAT:6.29, EXPENSIVE:1, Predicated:1, loss_labels [0.59554075]\n",
      "RM:6.781, LSTAT:7.67, EXPENSIVE:1, Predicated:1, loss_labels [0.53994655]\n",
      "RM:6.315, LSTAT:7.6, EXPENSIVE:0, Predicated:1, loss_labels [0.50560077]\n",
      "RM:5.648, LSTAT:14.1, EXPENSIVE:0, Predicated:0, loss_labels [0.11802529]\n",
      "RM:5.682, LSTAT:10.21, EXPENSIVE:0, Predicated:0, loss_labels [0.28549192]\n",
      "RM:6.162, LSTAT:24.1, EXPENSIVE:0, Predicated:0, loss_labels [0.00975255]\n",
      "RM:5.67, LSTAT:17.6, EXPENSIVE:0, Predicated:0, loss_labels [0.04844181]\n",
      "RM:6.98, LSTAT:11.66, EXPENSIVE:1, Predicated:0, loss_labels [0.29256037]\n",
      "RM:7.313, LSTAT:13.44, EXPENSIVE:0, Predicated:0, loss_labels [0.21995282]\n",
      "RM:6.879, LSTAT:9.93, EXPENSIVE:1, Predicated:0, loss_labels [0.39277305]\n",
      "RM:6.142, LSTAT:18.72, EXPENSIVE:0, Predicated:0, loss_labels [0.04188025]\n",
      "RM:6.616, LSTAT:8.93, EXPENSIVE:1, Predicated:0, loss_labels [0.43877479]\n",
      "RM:6.069, LSTAT:9.55, EXPENSIVE:0, Predicated:0, loss_labels [0.35361638]\n",
      "RM:6.398, LSTAT:7.79, EXPENSIVE:1, Predicated:0, loss_labels [0.49938371]\n",
      "RM:7.831, LSTAT:4.45, EXPENSIVE:1, Predicated:1, loss_labels [0.80381635]\n",
      "RM:7.42, LSTAT:6.47, EXPENSIVE:1, Predicated:1, loss_labels [0.67031183]\n",
      "RM:5.404, LSTAT:13.28, EXPENSIVE:0, Predicated:0, loss_labels [0.13407415]\n",
      "RM:6.03, LSTAT:18.8, EXPENSIVE:0, Predicated:0, loss_labels [0.03953614]\n",
      "RM:5.637, LSTAT:18.34, EXPENSIVE:0, Predicated:0, loss_labels [0.03936268]\n",
      "RM:6.302, LSTAT:6.72, EXPENSIVE:1, Predicated:1, loss_labels [0.56534498]\n",
      "RM:6.86, LSTAT:6.92, EXPENSIVE:1, Predicated:1, loss_labels [0.5975986]\n",
      "RM:6.152, LSTAT:15.02, EXPENSIVE:0, Predicated:0, loss_labels [0.10936544]\n",
      "RM:7.691, LSTAT:6.58, EXPENSIVE:1, Predicated:1, loss_labels [0.683609]\n",
      "RM:6.25, LSTAT:5.5, EXPENSIVE:1, Predicated:1, loss_labels [0.64217424]\n",
      "RM:7.416, LSTAT:6.19, EXPENSIVE:1, Predicated:1, loss_labels [0.68700577]\n",
      "RM:5.914, LSTAT:18.33, EXPENSIVE:0, Predicated:0, loss_labels [0.043167]\n",
      "RM:7.135, LSTAT:4.45, EXPENSIVE:1, Predicated:1, loss_labels [0.76414306]\n",
      "RM:5.813, LSTAT:14.81, EXPENSIVE:0, Predicated:0, loss_labels [0.10403588]\n",
      "RM:5.707, LSTAT:12.01, EXPENSIVE:0, Predicated:0, loss_labels [0.19626449]\n",
      "RM:5.536, LSTAT:23.6, EXPENSIVE:0, Predicated:0, loss_labels [0.00908076]\n",
      "RM:6.696, LSTAT:7.18, EXPENSIVE:1, Predicated:1, loss_labels [0.5665524]\n",
      "RM:6.86, LSTAT:6.92, EXPENSIVE:1, Predicated:1, loss_labels [0.5975986]\n",
      "RM:6.781, LSTAT:7.67, EXPENSIVE:1, Predicated:1, loss_labels [0.53994655]\n",
      "RM:6.642, LSTAT:9.69, EXPENSIVE:1, Predicated:0, loss_labels [0.38963676]\n",
      "RM:6.172, LSTAT:19.15, EXPENSIVE:1, Predicated:0, loss_labels [0.03769921]\n",
      "RM:5.757, LSTAT:17.31, EXPENSIVE:0, Predicated:0, loss_labels [0.05377383]\n",
      "RM:5.983, LSTAT:13.35, EXPENSIVE:0, Predicated:0, loss_labels [0.15583329]\n",
      "RM:5.39, LSTAT:21.14, EXPENSIVE:0, Predicated:0, loss_labels [0.01700297]\n",
      "RM:5.57, LSTAT:21.02, EXPENSIVE:0, Predicated:0, loss_labels [0.01864958]\n",
      "RM:5.713, LSTAT:14.76, EXPENSIVE:0, Predicated:0, loss_labels [0.10220273]\n",
      "RM:7.016, LSTAT:2.96, EXPENSIVE:1, Predicated:1, loss_labels [0.82491181]\n",
      "RM:6.824, LSTAT:22.74, EXPENSIVE:0, Predicated:0, loss_labels [0.01765925]\n",
      "RM:4.973, LSTAT:12.64, EXPENSIVE:0, Predicated:0, loss_labels [0.1379149]\n",
      "RM:6.513, LSTAT:10.29, EXPENSIVE:0, Predicated:0, loss_labels [0.34089467]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h4/7cr1cmpn7v5b3x20_9wz8m740000gn/T/ipykernel_17242/2755839443.py:8: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  predicate_label = int(predicate > decision_boundary)\n"
     ]
    }
   ],
   "source": [
    "random_test_indices = np.random.choice(range(len(rm)), size=100)\n",
    "decision_boundary = 0.5\n",
    "\n",
    "for i in random_test_indices:\n",
    "    x1, x2, y = rm[i], lstat[i], expensive[i]\n",
    "    predicate = model_r(np.array([x1, x2]), w_r, b_r)\n",
    "    loss_labels.append(predicate)\n",
    "    predicate_label = int(predicate > decision_boundary)\n",
    "\n",
    "    print('RM:{}, LSTAT:{}, EXPENSIVE:{}, Predicated:{}, loss_labels'.format(x1, x2, y, predicate_label), predicate)\n",
    "\n",
    "    true_labels.append(y)\n",
    "    predicated_labels.append(predicate_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(ytrues, yhats):\n",
    "    return sum(1 for yt, y1 in zip(ytrues, yhats) if yt == y1) / len(ytrues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(true_labels, predicated_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(ytrues, yhats):\n",
    "    # 预测标签是 1 的里面，正确的比例是多少\n",
    "\n",
    "    positives_pred = [y for y in yhats if y == 1]\n",
    "    return sum(1 for yt, y in zip(ytrues, yhats) if yt == y and y == 1) / len(positives_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8181818181818182"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision(true_labels, predicated_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(ytrues, yhats):\n",
    "    \n",
    "    true_positive = [y for y in ytrues if y == 1]     \n",
    "    return sum(1 for yt, y in zip(ytrues, yhats) if yt == y and yt == 1) / len(true_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(true_labels, predicated_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = [0] * 90 + [1] * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0] * 100\n",
    "b = [1] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(people, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/du/git/AI_Cheats/Core foundations/10.ipynb 单元格 23\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/du/git/AI_Cheats/Core%20foundations/10.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m precision(people, a)\n",
      "\u001b[1;32m/Users/du/git/AI_Cheats/Core foundations/10.ipynb 单元格 23\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/du/git/AI_Cheats/Core%20foundations/10.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprecision\u001b[39m(ytrues, yhats):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/du/git/AI_Cheats/Core%20foundations/10.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m# 预测标签是 1 的里面，正确的比例是多少\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/du/git/AI_Cheats/Core%20foundations/10.ipynb#X31sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     positives_pred \u001b[39m=\u001b[39m [y \u001b[39mfor\u001b[39;00m y \u001b[39min\u001b[39;00m yhats \u001b[39mif\u001b[39;00m y \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/du/git/AI_Cheats/Core%20foundations/10.ipynb#X31sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msum\u001b[39;49m(\u001b[39m1\u001b[39;49m \u001b[39mfor\u001b[39;49;00m yt, y \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(ytrues, yhats) \u001b[39mif\u001b[39;49;00m yt \u001b[39m==\u001b[39;49m y \u001b[39mand\u001b[39;49;00m y \u001b[39m==\u001b[39;49m \u001b[39m1\u001b[39;49m) \u001b[39m/\u001b[39;49m \u001b[39mlen\u001b[39;49m(positives_pred)\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "precision(people, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(people, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(people, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision(people, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(people, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_model = [true_labels, predicated_labels, loss_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('boston_labels', 'wb') as f:\n",
    "    pickle.dump(boston_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loss_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(true_labels), len(predicated_labels), len(loss_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![欢迎订阅：坍缩的奇点](../assets/Capture-2023-11-02-164446.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
